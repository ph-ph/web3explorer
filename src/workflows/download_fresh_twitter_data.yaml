main:
  steps:
    - constants:
        assign:
          - compute_influencer_watermarks_url: https://us-west1-web3twitterdata.cloudfunctions.net/compute_influencer_watermarks
          - download_new_tweets_and_likes_for_user_url: https://us-west1-web3twitterdata.cloudfunctions.net/download_new_tweets_and_likes_for_user
          - download_new_users_url: https://us-west1-web3twitterdata.cloudfunctions.net/download_new_users
          - upload_tweets_from_firestore_to_big_query_url: https://us-west1-web3twitterdata.cloudfunctions.net/upload_tweets_from_firestore_to_big_query
          - upload_likes_from_firestore_to_big_query_url: https://us-west1-web3twitterdata.cloudfunctions.net/upload_likes_from_firestore_to_big_query
          - upload_users_from_firestore_to_big_query_url: https://us-west1-web3twitterdata.cloudfunctions.net/upload_users_from_firestore_to_big_query
          - cleanup_firestore_data_url: https://us-west1-web3twitterdata.cloudfunctions.net/cleanup_firestore_data
        next: computeInfluencerWatermarks
    - computeInfluencerWatermarks:
        call: http.get
        args:
          url: ${compute_influencer_watermarks_url}
          auth:
              type: OIDC
        result: watermarksResponse
        next: logResponse
    - logResponse:
        call: sys.log
        args:
            text: ${watermarksResponse}
    - downloadNewTweetsAndLikes:
        for:
          value: watermark
          in: ${watermarksResponse.body.watermarks}
          steps:
            - downloadNewTweetsAndLikesForUser:
                call: http.post
                args:
                  url: ${download_new_tweets_and_likes_for_user_url}
                  body: ${watermark}
                  headers:
                    Content-Type: "application/json"
                  auth:
                    type: OIDC
                  timeout: 540
        next: downloadNewUsers
    - downloadNewUsers:
        call: http.post
        args:
          url: ${download_new_users_url}
          auth:
            type: OIDC
          timeout: 540
        next: uploadTweetsToBigQuery
    - uploadTweetsToBigQuery:
        call: http.post
        args:
          url: ${upload_tweets_from_firestore_to_big_query_url}
          auth:
            type: OIDC
          timeout: 540
        next: uploadLikesToBigQuery
    - uploadLikesToBigQuery:
        call: http.post
        args:
          url: ${upload_likes_from_firestore_to_big_query_url}
          auth:
            type: OIDC
          timeout: 540
        next: uploadUsersToBigQuery
    - uploadUsersToBigQuery:
        call: http.post
        args:
          url: ${upload_users_from_firestore_to_big_query_url}
          auth:
            type: OIDC
          timeout: 540
        next: createUsersNewTable
    - createUsersNewTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.users_new;
              CREATE TABLE TwitterData.users_new LIKE TwitterData.users;

              INSERT TwitterData.users_new
              WITH new_users_with_influencers AS (
                  SELECT
                      u.id,
                      u.username,
                      u.name,
                      i.username IS NOT NULL AS is_influencer
                  FROM TwitterDataRaw.users AS u
                  LEFT JOIN TwitterData.influencer_usernames_import AS i
                  ON u.username = i.username
                  WHERE u.ds = (SELECT MAX(ds) FROM TwitterDataRaw.users)
              )
              SELECT
                  COALESCE(e.id, n.id) AS id,
                  COALESCE(e.username, n.username) AS username,
                  COALESCE(e.name, n.name) AS name,
                  COALESCE(e.is_influencer, n.is_influencer) AS is_influencer
              FROM TwitterData.users AS e
              FULL OUTER JOIN new_users_with_influencers AS n
              ON e.id = n.id;
        next: exchangeUsersTable
    - exchangeUsersTable:
        call: conditionalExchange
        args:
          table_name: users
        next: createReferencedTweetsNewTable
    - createReferencedTweetsNewTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.referenced_tweets_new;
              CREATE TABLE TwitterData.referenced_tweets_new LIKE TwitterData.referenced_tweets;

              INSERT INTO TwitterData.referenced_tweets_new
              SELECT
                  COALESCE(e.tweet_id, n.tweet_id) AS tweet_id,
                  COALESCE(e.referenced_tweet_id, n.referenced_tweet_id) AS referenced_tweet_id,
                  COALESCE(e.type, n.type) AS type
              FROM TwitterData.referenced_tweets AS e
              FULL OUTER JOIN TwitterDataRaw.referenced_tweets AS n
              ON e.tweet_id = n.tweet_id AND e.referenced_tweet_id = n.referenced_tweet_id AND e.type = n.type
              WHERE n.ds IS NULL OR n.ds = (SELECT MAX(ds) FROM TwitterDataRaw.referenced_tweets)
        next: exchangeReferencedTweetsTable
    - exchangeReferencedTweetsTable:
        call: conditionalExchange
        args:
          table_name: referenced_tweets
        next: createLikesNewTable
    - createLikesNewTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.likes_new;
              CREATE TABLE TwitterData.likes_new LIKE TwitterData.likes;

              INSERT INTO TwitterData.likes_new
              WITH new_likes_hydrated AS (
                  SELECT
                      l.id AS tweet_id,
                      liked_by_user_id,
                      u.username AS liked_by_username,
                      created_at AS tweet_created_at,
                      u.is_influencer AS is_influencer_like
                  FROM TwitterDataRaw.likes AS l
                  LEFT JOIN TwitterData.users AS u
                  ON l.liked_by_user_id = u.id
                  WHERE l.ds = (SELECT MAX(ds) FROM TwitterDataRaw.likes) -- use the latest partition
              )
              SELECT
                  COALESCE(e.tweet_id, n.tweet_id) AS tweet_id,
                  COALESCE(e.liked_by_user_id, n.liked_by_user_id) AS liked_by_user_id,
                  COALESCE(e.liked_by_username, n.liked_by_username)  AS liked_by_username,
                  COALESCE(e.tweet_created_at, n.tweet_created_at) AS tweet_created_at,
                  COALESCE(e.is_influencer_like, n.is_influencer_like) AS is_influencer_like
              FROM TwitterData.likes AS e
              FULL OUTER JOIN new_likes_hydrated AS n
              ON e.tweet_id = n.tweet_id  AND e.liked_by_user_id = n.liked_by_user_id;
        next: exchangeLikesTable
    - exchangeLikesTable:
        call: conditionalExchange
        args:
          table_name: likes
        next: createTweetsNewTable
    - createTweetsNewTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.tweets_new;
              CREATE TABLE TwitterData.tweets_new LIKE TwitterData.tweets;

              INSERT INTO TwitterData.tweets_new
              WITH
              new_tweets AS (
                  SELECT
                      * EXCEPT(ds)
                  FROM TwitterDataRaw.tweets
                  WHERE ds = (SELECT MAX(ds) FROM TwitterDataRaw.tweets)
              ),
              hydrated_references AS (
                  SELECT
                      tweet_id,
                      referenced_tweet_id,
                      username,
                      type
                  FROM TwitterDataRaw.referenced_tweets AS rt
                  LEFT JOIN new_tweets AS t
                  ON rt.referenced_tweet_id = t.id
                  LEFT JOIN TwitterData.users AS u
                  ON t.author_id = u.id
                  WHERE rt.ds = (SELECT MAX(ds) FROM TwitterDataRaw.referenced_tweets)
              ),
              quotes AS (
                  SELECT
                      *
                  FROM hydrated_references WHERE type = 'quoted'
              ),
              replies AS (
                  SELECT
                      *
                  FROM hydrated_references WHERE type = 'replied_to'
              ),
              retweets AS (
                  SELECT
                      *
                  FROM hydrated_references WHERE type = 'retweeted'
              ),
              hydrated_new_tweets AS (
                  SELECT
                      t.id,
                      t.text,
                      t.created_at,
                      t.fetched_at,
                      t.author_id,
                      u.username AS author_username,
                      in_reply_to_user_id,
                      u1.username AS in_reply_to_username,
                      t.mentioned_hashtags,
                      t.mentioned_users AS mentioned_usernames,
                      t.mentioned_urls,
                      t.like_count,
                      t.retweet_count,
                      t.quote_count,
                      t.reply_count,
                      u.is_influencer AS is_by_influencer,
                      replies.referenced_tweet_id IS NOT NULL AS is_reply,
                      quotes.referenced_tweet_id IS NOT NULL AS is_quote,
                      retweets.referenced_tweet_id IS NOT NULL AS is_retweet,
                      (replies.username IS NOT NULL AND replies.username = u.username) AS is_selfreply,
                      (quotes.username IS NOT NULL AND quotes.username = u.username) AS is_selfquote,
                      replies.referenced_tweet_id AS replied_to_tweet_id,
                      quotes.referenced_tweet_id AS quoted_tweet_id,
                      retweets.referenced_tweet_id AS retweeted_tweet_id,
                      replies.username AS replied_to_username,
                      quotes.username AS quoted_username,
                      retweets.username AS retweeted_username
                  FROM new_tweets  AS t
                  LEFT JOIN TwitterData.users AS u
                  ON t.author_id = u.id
                  LEFT JOIN TwitterData.users AS u1
                  ON t.in_reply_to_user_id = u1.id
                  LEFT JOIN replies
                  ON t.id = replies.tweet_id
                  LEFT JOIN quotes
                  ON t.id = quotes.tweet_id
                  LEFT JOIN retweets
                  ON t.id = retweets.tweet_id
              )
              SELECT
                  COALESCE(e.id, n.id) AS id,
                  COALESCE(e.text, n.text) AS text,
                  COALESCE(e.created_at, n.created_at) AS created_at,
                  COALESCE(e.fetched_at, n.fetched_at) AS fetched_at,
                  COALESCE(e.author_id, n.author_id) AS author_id,
                  COALESCE(e.author_username, n.author_username) AS author_username,
                  COALESCE(e.in_reply_to_user_id, n.in_reply_to_user_id) AS in_reply_to_user_id,
                  COALESCE(e.in_reply_to_username, n.in_reply_to_username) AS in_reply_to_username,
                  COALESCE(e.mentioned_hashtags, n.mentioned_hashtags) AS mentioned_hashtags,
                  COALESCE(e.mentioned_usernames, n.mentioned_usernames) AS mentioned_usernames,
                  COALESCE(e.mentioned_urls, n.mentioned_urls) AS mentioned_urls,
                  COALESCE(e.like_count, n.like_count) AS like_count,
                  COALESCE(e.retweet_count, n.retweet_count) AS retweet_count,
                  COALESCE(e.quote_count, n.quote_count) AS quote_count,
                  COALESCE(e.reply_count, n.reply_count) AS reply_count,
                  COALESCE(e.is_by_influencer, n.is_by_influencer) AS is_by_influencer,
                  COALESCE(e.is_reply, n.is_reply) AS is_reply,
                  COALESCE(e.is_quote, n.is_quote) AS is_quote,
                  COALESCE(e.is_retweet, n.is_retweet) AS is_retweet,
                  COALESCE(e.is_selfreply, n.is_selfreply) AS is_selfreply,
                  COALESCE(e.is_selfquote, n.is_selfquote) AS is_selfquote,
                  COALESCE(e.replied_to_tweet_id, n.replied_to_tweet_id) AS replied_to_tweet_id,
                  COALESCE(e.quoted_tweet_id, n.quoted_tweet_id) AS quoted_tweet_id,
                  COALESCE(e.retweeted_tweet_id, n.retweeted_tweet_id) AS retweeted_tweet_id,
                  COALESCE(e.replied_to_username, n.replied_to_username) AS replied_to_username,
                  COALESCE(e.quoted_username, n.quoted_username) AS quoted_username,
                  COALESCE(e.retweeted_username, n.retweeted_username) AS retweeted_username
              FROM TwitterData.tweets AS e
              FULL OUTER JOIN hydrated_new_tweets AS n
              ON e.id = n.id
              WHERE COALESCE(e.author_username, n.author_username) IS NOT NULL -- working around some edge case
        next: exchangeTweetsTable
    - exchangeTweetsTable:
        call: conditionalExchange
        args:
          table_name: tweets
        next: createWordMentionsTable
    - createWordMentionsTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.word_mentions;

              CREATE TABLE TwitterData.word_mentions (
                  word STRING NOT NULL OPTIONS(description="lowercase word mentioned in the tweet text"),
                  id INT64 NOT NULL OPTIONS(description="Id of tweet"),
                  text STRING NOT NULL OPTIONS(description="Text of tweet, including newlines and emojis"),
                  created_at TIMESTAMP NOT NULL OPTIONS(description="Creation timestamp"),
                  fetched_at TIMESTAMP NOT NULL OPTIONS(description="Timestamp of when the tweet data was fetched. Important for determining maturity of engagement metrics"),
                  author_id INT64 NOT NULL OPTIONS(description="User id of tweet author"),
                  author_username STRING NOT NULL OPTIONS(description="Username of tweet author"),
                  in_reply_to_user_id INT64 OPTIONS(description="If this tweet is a reply, id of the author of the original tweet. NULL otherwise"),
                  in_reply_to_username STRING OPTIONS(description="If this tweet is a reply, username of the author of the original tweet. NULL otherwise"),
                  mentioned_hashtags ARRAY<STRING> OPTIONS(description="Array of hashtags that are mentioned in the tweet"),
                  mentioned_usernames ARRAY<STRING> OPTIONS(description="Array of usernames that are mentioned in the tweet, without leading @"),
                  mentioned_urls ARRAY<STRING> OPTIONS(description="Array of expanded urls that are mentioned in the tweet"),
                  like_count INT64 NOT NULL OPTIONS(description="Number of likes for the tweet. Depends on when the tweet data was fetched"),
                  retweet_count INT64 NOT NULL OPTIONS(description="Number of retweets for the tweet. Depends on when the tweet data was fetched"),
                  quote_count INT64 NOT NULL OPTIONS(description="Number of times this tweet was quoted. Depends on when the tweet data was fetched"),
                  reply_count INT64 NOT NULL OPTIONS(description="Number of replies to this tweet. Depends on when the tweet data was fetched"),
                  is_by_influencer BOOLEAN NOT NULL OPTIONS(description="True if the tweet is by a user from our list of influencers"),
                  is_reply BOOLEAN NOT NULL OPTIONS(description="True if the tweet is a reply to other tweet"),
                  is_quote BOOLEAN NOT NULL OPTIONS(description="True if the tweet is quoting another tweet"),
                  is_retweet BOOLEAN NOT NULL OPTIONS(description="True if the tweet is a retweet"),
                  is_selfreply BOOLEAN NOT NULL OPTIONS(description="True if the tweet replies to a tweet by the same author"),
                  is_selfquote BOOLEAN NOT NULL OPTIONS(description="True if the tweet quotes a tweet by the same author"),
                  replied_to_tweet_id INT64 OPTIONS(description="Id of the tweet replied to by this tweet"),
                  quoted_tweet_id INT64 OPTIONS(description="Id of the tweet quoted by this tweet"),
                  retweeted_tweet_id INT64 OPTIONS(description="Id of the tweet retweeted by this tweet"),
                  replied_to_username STRING OPTIONS(description="Username of author of the tweet that this tweet replies to"),
                  quoted_username STRING OPTIONS(description="Username of author of the tweet that this tweet quotes"),
                  retweeted_username STRING OPTIONS(description="Username of author of the tweet that this tweet retweets")
              )
              OPTIONS(
                  description="A table with one row for each word occurrence in a tweet. The set of tweets is the same as in the tweets table. If a word occurs more than once in a tweet, only one row will be created for this word-tweet combination."
              )
              AS
              WITH tweets_with_word_bags AS (
                  SELECT
                      -- Ok, this is crazy, so let me explain what's going on here
                      -- We first lowercase tweet's text and replace newlines with spaces
                      -- we then split it by spaces into words
                      -- we then "unnest" the resulting array into table - this gives us a table with row per word
                      -- we then remove leading and trailing punctuation from each word, so that "dao:" and "@dao." turn into "dao"
                      -- we then select unique words and turn them back into an array, and we call this array "words"
                      ARRAY(SELECT DISTINCT TRIM(TRIM(word), ",.!?:\"'") FROM UNNEST(SPLIT(TRANSLATE(LOWER(text), "\n", " "), " ")) AS word) AS words,
                      tweets.*
                  FROM `web3twitterdata.TwitterData.tweets` AS tweets
              )
              SELECT
                  word,
                  tweets_with_word_bags.* EXCEPT(words)
              FROM tweets_with_word_bags
              CROSS JOIN UNNEST(words) AS word
              WHERE TRIM(TRIM(word), ",.!?:") != '';
        next: createWordMentionStatsTable
    - createWordMentionStatsTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 540000
            query: |
              DROP TABLE IF EXISTS TwitterData.word_mention_stats;

              CREATE TABLE `web3twitterdata.TwitterData.word_mention_stats`
              (
                  word STRING NOT NULL OPTIONS(description="word mentioned in a tweet"),
                  week_start DATE NOT NULL OPTIONS(description="weekly snapshot date"),
                  week_num INT64 NOT NULL OPTIONS(description="zero-based number of the snapshot"),
                  mentions_before INT64 NOT NULL OPTIONS(description="number of times the word was mentioned before the snapshot date"),
                  influencer_mentions_before INT64 NOT NULL OPTIONS(description="number of times the word was mentioned by influencers before the snapshot date"),
                  quotes_before INT64 NOT NULL OPTIONS(description="total number of quotes for tweets mentioning the word before the snapshot date"),
                  influencer_quotes_before INT64 NOT NULL OPTIONS(description="total number of quotes for influencer tweets mentioning the word before the snapshot date"),
                  norm_mentions_before FLOAT64 NOT NULL OPTIONS(description="normalized number of times the word was mentioned before the snapshot date"),
                  norm_influencer_mentions_before FLOAT64 NOT NULL OPTIONS(description="normalized number of times the word was mentioned by influencers before the snapshot date"),
                  norm_quotes_before FLOAT64 NOT NULL OPTIONS(description="normalized total number of quotes for tweets mentioning the word before the snapshot date"),
                  norm_influencer_quotes_before FLOAT64 NOT NULL OPTIONS(description="normalized total number of quotes for influencer tweets mentioning the word before the snapshot date"),
                  mentions_after INT64 NOT NULL OPTIONS(description="number of times the word was mentioned on or after the snapshot date"),
                  influencer_mentions_after INT64 NOT NULL OPTIONS(description="number of times the word was mentioned by influencers on or after the snapshot date"),
                  quotes_after INT64 NOT NULL OPTIONS(description="total number of quotes for tweets mentioning the word on or after the snapshot date"),
                  influencer_quotes_after INT64 NOT NULL OPTIONS(description="total number of quotes for influencer tweets mentioning the word on or after the snapshot date"),
                  norm_mentions_after FLOAT64 NOT NULL OPTIONS(description="normalized number of times the word was mentioned on or after the snapshot date"),
                  norm_influencer_mentions_after FLOAT64 NOT NULL OPTIONS(description="normalized number of times the word was mentioned by influencers on or after the snapshot date"),
                  norm_quotes_after FLOAT64 NOT NULL OPTIONS(description="normalized total number of quotes for tweets mentioning the word on or after the snapshot date"),
                  norm_influencer_quotes_after FLOAT64 NOT NULL OPTIONS(description="normalized total number of quotes for influencer tweets mentioning the word on or after the snapshot date")
              )
              OPTIONS(
                description="Snapshots of stats for words mentioned in the tweets from the tweets table. Snapshots are taken once a week, starting from 2021-10-01. Stats capture how often a word was mentioned before and after the snapshot date"
              )
              AS
              WITH
              dates AS (
                  SELECT
                      week_start, week_num
                  FROM UNNEST(GENERATE_DATE_ARRAY('2021-10-01', '2021-12-01', INTERVAL 1 WEEK)) AS week_start WITH OFFSET AS week_num
              ),
              words AS (
                  SELECT
                      DISTINCT word
                  FROM TwitterData.word_mentions
              ),
              words_with_dates AS (
                  SELECT
                      word,
                      week_start,
                      week_num
                  FROM words CROSS JOIN dates
              ),
              mentions_before AS (
                  SELECT
                      wwd.word,
                      week_start,
                      week_num,
                      COUNT(1) AS mentions_before,
                      COUNTIF(is_by_influencer) AS influencer_mentions_before,
                      SUM(quote_count) AS quotes_before,
                      SUM(IF(is_by_influencer, quote_count, 0)) AS influencer_quotes_before,
                      COUNT(1)/(week_num + 1) AS norm_mentions_before,
                      COUNTIF(is_by_influencer)/(week_num + 1) AS norm_influencer_mentions_before,
                      SUM(quote_count)/(week_num + 1) AS norm_quotes_before,
                      SUM(IF(is_by_influencer, quote_count, 0))/(week_num + 1) AS norm_influencer_quotes_before,
                  FROM words_with_dates AS wwd
                  JOIN TwitterData.word_mentions AS wm
                  ON wwd.word = wm.word
                  WHERE DATE(wm.created_at) < week_start AND DATE(wm.created_at) >= "2021-09-24"
                  GROUP BY 1, 2, 3
              ),
              mentions_after AS (
                  SELECT
                      wwd.word,
                      week_start,
                      week_num,
                      COUNT(1) AS mentions_after,
                      COUNTIF(is_by_influencer) AS influencer_mentions_after,
                      SUM(quote_count) AS quotes_after,
                      SUM(IF(is_by_influencer, quote_count, 0)) AS influencer_quotes_after,
                      COUNT(1)/(9 - week_num) AS norm_mentions_after,
                      COUNTIF(is_by_influencer)/(9 - week_num) AS norm_influencer_mentions_after,
                      SUM(quote_count)/(9 - week_num) AS norm_quotes_after,
                      SUM(IF(is_by_influencer, quote_count, 0))/(9 - week_num) AS norm_influencer_quotes_after,
                  FROM words_with_dates AS wwd
                  JOIN TwitterData.word_mentions AS wm
                  ON wwd.word = wm.word
                  WHERE DATE(wm.created_at) >= week_start
                  GROUP BY 1, 2, 3
              )
              SELECT
                  COALESCE(mb.word, ma.word) AS word,
                  COALESCE(mb.week_start, ma.week_start) AS week_start,
                  COALESCE(mb.week_num, ma.week_num) AS week_num,
                  COALESCE(mb.mentions_before, 0) AS mentions_before,
                  COALESCE(mb.influencer_mentions_before, 0) AS influencer_mentions_before,
                  COALESCE(mb.quotes_before, 0) AS quotes_before,
                  COALESCE(mb.influencer_quotes_before, 0) AS influencer_quotes_before,
                  COALESCE(mb.norm_mentions_before, 0) AS norm_mentions_before,
                  COALESCE(mb.norm_influencer_mentions_before, 0) AS norm_influencer_mentions_before,
                  COALESCE(mb.norm_quotes_before, 0) AS norm_quotes_before,
                  COALESCE(mb.norm_influencer_quotes_before, 0) AS norm_influencer_quotes_before,
                  COALESCE(ma.mentions_after, 0) AS mentions_after,
                  COALESCE(ma.influencer_mentions_after, 0) AS influencer_mentions_after,
                  COALESCE(ma.quotes_after, 0) AS quotes_after,
                  COALESCE(ma.influencer_quotes_after, 0) AS influencer_quotes_after,
                  COALESCE(ma.norm_mentions_after, 0) AS norm_mentions_after,
                  COALESCE(ma.norm_influencer_mentions_after, 0) AS norm_influencer_mentions_after,
                  COALESCE(ma.norm_quotes_after, 0) AS norm_quotes_after,
                  COALESCE(ma.norm_influencer_quotes_after, 0) AS norm_influencer_quotes_after,
              FROM mentions_before AS mb
              FULL OUTER JOIN mentions_after AS ma
              ON mb.word = ma.word AND mb.week_start = ma.week_start;
        next: cleanupFirestoreData
    - cleanupFirestoreData:
        call: http.post
        args:
          url: ${cleanup_firestore_data_url}
          auth:
            type: OIDC
          timeout: 540
        next: end



conditionalExchange:
  params: ["table_name"]
  steps:
    - checkIfNewTableHasMoreRows:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 60000
            query: ${"SELECT (SELECT COUNT(1) FROM TwitterData." + table_name + ") < (SELECT COUNT(1) FROM TwitterData." + table_name + "_new)"}
        result: queryResult
    - checkResult:
        switch:
          - condition: ${queryResult.rows[0].f[0].v == "true"}
            next: exchangeTable
        next: failedExchange
    - exchangeTable:
        call: googleapis.bigquery.v2.jobs.query
        args:
          projectId: web3twitterdata
          body:
            maxResults: 10
            useLegacySql: false
            timeoutMs: 60000
            query: ${"DROP TABLE IF EXISTS TwitterData." + table_name + "_old; ALTER TABLE TwitterData." + table_name + " RENAME TO " + table_name + "_old; ALTER TABLE TwitterData." + table_name +"_new RENAME TO " + table_name}
    - failedExchange:
        return: ${"Failed to replace table TwitterData." + table_name}
        next: end
